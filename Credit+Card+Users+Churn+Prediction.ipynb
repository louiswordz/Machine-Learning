{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b1f70f",
   "metadata": {},
   "source": [
    "# Credit Card Users Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d8b9e",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The Thera bank recently saw a steep decline in the number of users of their credit card, credit cards are a good source of income for banks because of different kinds of fees charged by the banks like annual fees, balance transfer fees, and cash advance fees, late payment fees, foreign transaction fees, and others. Some fees are charged to every user irrespective of usage, while others are charged under specified circumstances.\n",
    "\n",
    "Customers’ leaving credit cards services would lead bank to loss, so the bank wants to analyze the data of customers and identify the customers who will leave their credit card services and reason for same – so that bank could improve upon those areas\n",
    "\n",
    "You as a Data scientist at Thera bank need to come up with a classification model that will help the bank improve its services so that customers do not renounce their credit cards\n",
    "\n",
    "**You need to identify best possible model that will give the required performance**\n",
    "\n",
    "\n",
    "## Data Description\n",
    "* CLIENTNUM: Client number. Unique identifier for the customer holding the account \n",
    "* Attrition_Flag: Internal event (customer activity) variable - if the account is closed then \"Attrited Customer\" else \"Existing Customer\" \n",
    "* Customer_Age: Age in Years\n",
    "* Gender: Gender of the account holder\n",
    "* Dependent_count: Number of dependents \n",
    "* Education_Level: Educational Qualification of the account holder - Graduate, High School, Unknown, Uneducated, College(refers to college student), Post-Graduate, Doctorate\n",
    "* Marital_Status: Marital Status of the account holder\n",
    "* Income_Category: Annual Income Category of the account holder\n",
    "* Card_Category: Type of Card\n",
    "* Months_on_book: Period of relationship with the bank (in months)\n",
    "* Total_Relationship_Count: Total no. of products held by the customer\n",
    "* Months_Inactive_12_mon: No. of months inactive in the last 12 months\n",
    "* Contacts_Count_12_mon: No. of Contacts in the last 12 months\n",
    "* Credit_Limit: Credit Limit on the Credit Card\n",
    "* Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n",
    "* Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n",
    "* Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n",
    "* Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n",
    "* Total_Trans_Ct: Total Transaction Count (Last 12 months)\n",
    "* Total_Ct_Chng_Q4_Q1: Change in Transaction Count (Q4 over Q1)\n",
    "* Avg_Utilization_Ratio: Average Card Utilization Ratio\n",
    "\n",
    "\n",
    "#### What Is a Revolving Balance?\n",
    "\n",
    "* If we don't pay the balance of the revolving credit account in full every month, the unpaid portion carries over to the next month. That's called a revolving balance\n",
    "\n",
    "\n",
    "#### What is the Average Open to buy?\n",
    "\n",
    "* 'Open to Buy' means the amount left on your credit card to use. Now, this column represents the average of this value for the last 12 months.\n",
    "\n",
    "#### What is the Average utilization Ratio?\n",
    "\n",
    "* The Avg_Utilization_Ratio represents how much of the available credit the customer spent. This is useful for calculating credit scores.\n",
    "\n",
    "\n",
    "#### Relation b/w Avg_Open_To_Buy, Credit_Limit and Avg_Utilization_Ratio:\n",
    "\n",
    "* ( Avg_Open_To_Buy / Credit_Limit ) + Avg_Utilization_Ratio = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd47da",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d299a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "# setting the precision of floating numbers to 5 decimal points\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)\n",
    "\n",
    "# To tune model, get different metric scores, and split data\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#to build SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d89e6a",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b3c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv(\"BankChurners.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84360d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns in the data\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44351c2",
   "metadata": {},
   "source": [
    "* The dataset has 10127 rows and 21 columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052ed25",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4467d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a copy of the data\n",
    "data = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2dd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's view the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2871b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's view the last 5 rows of the data\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the data types of the columns in the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914f9c7",
   "metadata": {},
   "source": [
    "* There are no null values in the Education_Level and Marital_Status\n",
    "* 5 columns are of object type rest all are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for duplicate values in the data\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8916dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for missing values in the data\n",
    "round(data.isnull().sum() / data.isnull().count() * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a3d73",
   "metadata": {},
   "source": [
    "- Education_Level has 15% missing values\n",
    "- Marital_Status has 7% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's view the statistical summary of the numerical columns in the data\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b21d42",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "* CLIENTNUM: It is a unique identifier for customers and can be dropped as it wouldn't add any information to our analysis.\n",
    "* Customer_Age: Average age of customers is 46 years, age of customers has a wide range from 26 to 73 years.\n",
    "* Dependent_count: On average the customers in the data have 2 dependents and a maximum of 5 dependents.\n",
    "* Months_on_book: All the customers of the bank have at least been with them for a year and 50% of the customers for at least 3 years.\n",
    "* Total_Relationship_Count: All customers use at least one product of the bank, whereas 75% of customers use 5 or fewer products of the bank.\n",
    "* Months_Inactive_12_mon: On average customers were inactive for two months in the past 12 months - this shows that the bank customers are active in transactions or usage of cards it would be interesting to see if high inactivity leads to churning of a customer.\n",
    "* Contacts_Count_12_mon: On average bank and customers interacted twice in the past 12 months.\n",
    "* Credit_Limit: There's a huge difference between the third quartile and maximum value. The range of credit limit is very wide from 1438 to 34516, customers with high credit limit might be outliers.\n",
    "* Total_Revolving_Bal: Average revolving balance of customers is 1162, there's not much difference in the third quartile and maximum value.\n",
    "* Avg_Open_To_Buy: Average amount that goes unused by the customers is 7469, the range is very wide for this variable and the extreme values(min and max) might be outliers.\n",
    "* Total_Amt_Chng_Q4_Q1: For 75% of the customers the transaction amount in Q4 was less than the transaction amount in Q1 (as value is equal to ~0.9).\n",
    "* Total_Trans_Amt: Average transaction amount of last 12 months is 4404, some customers spent as little as 510 while some customers made the transaction of more than 18k.\n",
    "* Total_Trans_Ct: On average customers made 64 or fewer transactions while 75% of the customers made 81 transactions.\n",
    "* Total_Ct_Chng_Q4_Q1: For 75% of the customers the number of transactions in Q4 was less than the transactions made in Q1.\n",
    "* Avg_Utilization_Ratio: On average customers used ~27% of the available credit amount of their card, with 75% of the customers utilizing 50% or less of their available credit amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=[\"object\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d144dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.describe(include=[\"object\"]).columns:\n",
    "    print(\"Unique values in\", i, \"are :\")\n",
    "    print(data[i].value_counts())\n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08544a10",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "* Most of the records are for existing customers.\n",
    "* Most of the bank's customers are female\n",
    "* Most customers are graduates.\n",
    "* Most customers are married.\n",
    "* Most customers lie in the income group of less than $40k \n",
    "* Most customers have a blue card.\n",
    "\n",
    "**Missing values**\n",
    "* 'abc' value of Income_Category can be considered and treated as missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfc8e2",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d91be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENTNUM consists of uniques ID for clients and hence will not add value to the modeling\n",
    "data.drop([\"CLIENTNUM\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ebb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding Existing and Attrited customers to 0 and 1 respectively, for analysis.\n",
    "data[\"Attrition_Flag\"].replace(\"Existing Customer\", 0, inplace=True)\n",
    "data[\"Attrition_Flag\"].replace(\"Attrited Customer\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b12fe7",
   "metadata": {
    "colab_type": "text",
    "id": "kUJ_B5KxhU3D"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8059d4",
   "metadata": {
    "colab_type": "text",
    "id": "7Rwx-1ZuhU3D"
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa114ca",
   "metadata": {},
   "source": [
    "Let's explore these variables in some more depth by observing their distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad547312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating numerical columns\n",
    "num_cols=['Customer_Age', 'Months_on_book', 'Credit_Limit', 'Total_Revolving_Bal','Avg_Open_To_Buy','Total_Trans_Ct','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Ct_Chng_Q4_Q1','Avg_Utilization_Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.set(style=\"darkgrid\")\n",
    "# Add a graph in each part\n",
    "sns.boxplot(data[\"Customer_Age\"], ax=ax_box)\n",
    "sns.distplot(data[\"Customer_Age\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Customer Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e8a69",
   "metadata": {},
   "source": [
    "### Observations on Customer_Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e55de",
   "metadata": {},
   "source": [
    "* The distribution of Customer_Age is normally distributed with mean and median at 46 years.\n",
    "* From the boxplot, we can see that there are a few outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269aa287",
   "metadata": {},
   "source": [
    "### Observations on Months_on_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609925ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Months_on_book\"], ax=ax_box)\n",
    "sns.distplot(data[\"Months_on_book\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Months_on_book')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb46c56",
   "metadata": {},
   "source": [
    "* Most customers are with the bank for 3 years.\n",
    "* From the boxplot, we can see that there are outliers on both sides of the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73663521",
   "metadata": {},
   "source": [
    "### Observations on Credit_Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Credit_Limit\"], ax=ax_box)\n",
    "sns.distplot(data[\"Credit_Limit\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Credit_Limit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8441c1b",
   "metadata": {},
   "source": [
    "* The distribution of the Credit_Limit is skewed to the right.\n",
    "* There are quite a few customers with a maximum Credit Limit of 35000.\n",
    "* 50% of the customers of the bank have a credit limit of less than <5000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba8276",
   "metadata": {},
   "source": [
    "### Observations on Total_Revolving_Bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0068f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Total_Revolving_Bal\"], ax=ax_box)\n",
    "sns.distplot(data[\"Total_Revolving_Bal\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Total_Revolving_Bal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea9a21",
   "metadata": {},
   "source": [
    "* Most customers pay the complete dues of credit card and have 0 revolving balance.\n",
    "* There are quite a few customers with a revolving balance of 2500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda0957",
   "metadata": {},
   "source": [
    "### Observations on Avg_Open_To_Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Avg_Open_To_Buy\"], ax=ax_box)\n",
    "sns.distplot(data[\"Avg_Open_To_Buy\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Avg_Open_To_Buy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04388ae",
   "metadata": {},
   "source": [
    "* The distribution of the Avg_Open_To_Buy column is right-skewed.\n",
    "* A right-skewed distribution indicates that most customers used a big part of their limit while only a few customers (on the right tail) were left with a majority of their credit amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaab933",
   "metadata": {},
   "source": [
    "### Observations on Total_Trans_Ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Total_Trans_Ct\"], ax=ax_box)\n",
    "sns.distplot(data[\"Total_Trans_Ct\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Total_Trans_Ct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe0df1",
   "metadata": {},
   "source": [
    "* The distribution of Total_Trans_Ct shows two peaks on 40 and 80 transactions in a year which indicates that customers used credit cards 3 to 6 times a month to make transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553dbb46",
   "metadata": {},
   "source": [
    "### Observations on Total_Amt_Chng_Q4_Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44420f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Total_Amt_Chng_Q4_Q1\"], ax=ax_box)\n",
    "sns.distplot(data[\"Total_Amt_Chng_Q4_Q1\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Total_Amt_Chng_Q4_Q1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30683bf",
   "metadata": {},
   "source": [
    "* The distribution of Total_Amt_Chng_Q4_Q1 looks normally distributed but there's a slight skew towards the right.\n",
    "* From the boxplot, we can see that there are outliers on both sides of the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041c944",
   "metadata": {},
   "source": [
    "### Observations on Total_Trans_Amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4010007",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Total_Trans_Amt\"], ax=ax_box)\n",
    "sns.distplot(data[\"Total_Trans_Amt\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Total_Trans_Amt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58cd61",
   "metadata": {},
   "source": [
    "* The distribution of Total_Trans_Amt is skewed to the right.\n",
    "* There are two peaks in data at total transaction amounts of one around 2500 and the second around the mean value of ~4500.\n",
    "* From the boxplot, we can see that there are outliers - customers with more than ~8000 total transaction amounts are being considered as outliers.\n",
    "* It would be interesting to check if the customers spending less with the card are the ones churning or the ones spending more are churning, if the latter is the case then there is a problem for the bank as it is losing valuable customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1663fd",
   "metadata": {},
   "source": [
    "### Observations on Total_Ct_Chng_Q4_Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b71fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Total_Ct_Chng_Q4_Q1\"], ax=ax_box)\n",
    "sns.distplot(data[\"Total_Ct_Chng_Q4_Q1\"], ax=ax_hist)\n",
    "ax_box.set(xlabel='Total_Ct_Chng_Q4_Q1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ade95",
   "metadata": {},
   "source": [
    "* The distribution of Total_Ct_Chng_Q4_Q1 looks normally distributed but there's a slight skew towards the right.\n",
    "* From the boxplot, we can see that there are outliers on both sides of the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1badb6",
   "metadata": {},
   "source": [
    "### Observations on Avg_Utilization_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxplot(data[\"Avg_Utilization_Ratio\"], ax=ax_box)\n",
    "sns.distplot(data[\"Avg_Utilization_Ratio\"], ax=ax_hist)\n",
    "ax_box.set(xlabel=' Avg_Utilization_Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068dff7",
   "metadata": {},
   "source": [
    "* The distribution of Avg_Utilization_Ratio is skewed to the right.\n",
    "* This distribution is not a positive sign for the bank as most of the customers are not utilizing their credit amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cca9a",
   "metadata": {},
   "source": [
    "**Credit limit, Average open to buy and Average utilization ratio are right-skewed**\n",
    "\n",
    "1. Open to buy means how much credit a customer is left with\n",
    "   * Low values of Open to buy could represent either\n",
    "       * Customers have low credit limits\n",
    "       * Customers are spending a lot so they are left less open to buy\n",
    "       \n",
    "\n",
    "2. Average utilization ratio = (1 - (open to buy/credit limit))\n",
    "   * Low values of the Average utilization ratio represents\n",
    "        * (Open to buy/credit limit) is nearly equal to 1 -> Open to buy is nearly equal to the credit limit -> customers are spending less using their credit cards\n",
    "\n",
    "3. Credit limit is also right-skewed which represents - most of the customers have low credit limits\n",
    " \n",
    "\n",
    "Looking at the 3 variables, we can conclude that most of the customers have low credit limits and are not utilizing their credit cards much\n",
    "\n",
    "Now this statement justifies the right skewness for all 3 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309bddb",
   "metadata": {
    "colab_type": "text",
    "id": "beo_tDmVhU3-"
   },
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(data.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5d5ae",
   "metadata": {},
   "source": [
    "* Attrition_Flag shows a bit of a negative correlation with Total_Trans_Ct (total transactions) and Total_Trans_Amt (total transaction amount).\n",
    "* There's a strong positive correlation between Months_on_book and Customer_Age, Total_Revolving_Bal and Avg_Utilization_Ratio, Total_Trans_Amt and Total_Trans_Ct.\n",
    "* There's a negative correlation of Total_Relationship_count with Total_Trans_Amt and Total_Trans_Ct, Avg_Utilization_Ratio with Credit_Limit and Avg_Open_To_Buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4084e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_cols= ['Gender','Marital_Status','Education_Level','Income_Category','Card_Category','Contacts_Count_12_mon', 'Months_Inactive_12_mon',\n",
    "            'Total_Relationship_Count','Dependent_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff35fd",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Gender'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bb885",
   "metadata": {},
   "source": [
    "* There's not much difference in attrition percentages for Males and Females.\n",
    "* ~20% of both Males and Females attrite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f054fd",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Marital_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81307a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Marital_Status'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8215aeb",
   "metadata": {},
   "source": [
    "* There's not much difference in attrition percentages for Marital_Status.\n",
    "* ~20% of Singles, Divorced attrite.\n",
    "* Married customers attrite the least."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183abd5",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Education_Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Education_Level'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba1856",
   "metadata": {},
   "source": [
    "* Customers with higher education -  Doctorates and Post Graduates are the ones most(~20% for both education levels) attriting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5a18c",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Income_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea07fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Income_Category'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f681891",
   "metadata": {},
   "source": [
    "* The customers from two extreme income groups - Earning less than 40K and Earning more than 120k+ are the ones attriting the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208198b",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Card_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Card_Category'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6049b",
   "metadata": {},
   "source": [
    "* ~35% of attrition is amongst the customers with platinum cards followed by ~30% attrition in Gold cards.\n",
    "* Customers with Platinum and Gold cards are our premium customers and the highest attrition for these customers is alarming as they are using the premium card provided by the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e89e0",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Contacts_Count_12_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a034dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Contacts_Count_12_mon'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9b275",
   "metadata": {},
   "source": [
    "* Highest attrition is among the customers who interacted the most with the bank.\n",
    "* This signifies that the bank is not able to resolve the problems faced by customers leading to attrition\n",
    "* A preliminary step to identify attriting customers would be to look out for customers who have reached out to them repeatedly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3e9b4",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Months_Inactive_12_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d121b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Months_Inactive_12_mon'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8be8af",
   "metadata": {},
   "source": [
    "* As inactivity increases attrition also increases (2-4 months)\n",
    "* The interpretation from here for 0 months and 6 months is difficult as customers who recently used the card attrited the most while those who were inactive for 6 months attrited less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dc25d",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Total_Relationship_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Total_Relationship_Count'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4a132",
   "metadata": {},
   "source": [
    "* Attrition is highest among the customers who are using 1 or 2 products offered by the bank - together they constitute ~55% of the attrition.\n",
    "* Customers who use more than 3 products are the ones least attriting, such customers might be more financially stable and actively invest in different services provided by the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cab51",
   "metadata": {},
   "source": [
    "### Attrition_Flag vs Dependent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb54ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.crosstab(data['Dependent_count'],data['Attrition_Flag'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13c168",
   "metadata": {},
   "source": [
    "* More the number of dependents more is the attrition, more responsibilities might lead to financial instability in such customers.\n",
    "* Attrition is fairly low for customers with 0 or 1 dependents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742c6e1",
   "metadata": {},
   "source": [
    "### Let's find the percentage of outliers, in each column of the data, using IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)  # To find the 25th percentile and 75th percentile.\n",
    "Q3 = data.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1  # Inter Quantile Range (75th perentile - 25th percentile)\n",
    "\n",
    "lower = (\n",
    "    Q1 - 1.5 * IQR\n",
    ")  # Finding lower and upper bounds for all values. All values outside these bounds are outliers\n",
    "upper = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f836e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (data.select_dtypes(include=[\"float64\", \"int64\"]) < lower)\n",
    "    | (data.select_dtypes(include=[\"float64\", \"int64\"]) > upper)\n",
    ").sum() / len(data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761169e",
   "metadata": {},
   "source": [
    "* After identifying outliers, we can decide whether to remove/treat them or not. It depends on one's approach, here we are not going to treat them as there will be outliers in real case scenario (in age, the total amount of transactions, number of transactions, etc) and we would want our model to learn the underlying pattern for such customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5326b",
   "metadata": {},
   "source": [
    "### Missing value imputation\n",
    "- We will first replace 'abc' values with 'np.nan' in Income_Category\n",
    "- We will impute missing values in all 3 columns using mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d18064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Income_Category\"].replace(\"abc\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b760d",
   "metadata": {},
   "source": [
    "* Values have been replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191604ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop([\"Attrition_Flag\"], axis=1)\n",
    "y = data1[\"Attrition_Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41de645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqd_col_for_impute = [\"Education_Level\", \"Marital_Status\", \"Income_Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the train data\n",
    "X_train[reqd_col_for_impute] = imputer.fit_transform(X_train[reqd_col_for_impute])\n",
    "\n",
    "# Transform the test data\n",
    "X_test[reqd_col_for_impute] = imputer.transform(X_test[reqd_col_for_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37700cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that no column has missing values in train or test sets\n",
    "print(X_train.isna().sum())\n",
    "print(\"-\" * 30)\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7419a",
   "metadata": {},
   "source": [
    "* All missing values have been treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.select_dtypes(include=[\"object\", \"category\"])\n",
    "for i in cols.columns:\n",
    "    print(X_train[i].value_counts())\n",
    "    print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f793016",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_test.select_dtypes(include=[\"object\", \"category\"])\n",
    "for i in cols.columns:\n",
    "    print(X_train[i].value_counts())\n",
    "    print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9f030",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a809b66",
   "metadata": {},
   "source": [
    "* After encoding there are 29 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ea6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8bbc6",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22471275",
   "metadata": {},
   "source": [
    "## Model evaluation criterion\n",
    "\n",
    "### Model can make wrong predictions as:\n",
    "1. Predicting a customer will attrite and the customer doesn't attrite\n",
    "2. Predicting a customer will not attrite and the customer attrites\n",
    "\n",
    "### Which case is more important? \n",
    "* Predicting that customer will not attrite but he attrites i.e. losing on a valuable customer or asset. \n",
    "\n",
    "### How to reduce this loss i.e need to reduce False Negatives?\n",
    "* Bank would want `Recall` to be maximized, greater the Recall higher the chances of minimizing false negatives. Hence, the focus should be on increasing Recall or minimizing the false negatives or in other words identifying the true positives(i.e. Class 1) so that the bank can retain their valuable customers by identifying the customers who are at risk of attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf017c",
   "metadata": {},
   "source": [
    "**Also, let's create a function to calculate and print the classification report and confusion matrix so that we don't have to rewrite the same code repeatedly for each model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92559f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating metric function \n",
    "def metrics_score(actual, predicted):\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Attrite', 'Attrite'], yticklabels=['Not Attrite', 'Attrite'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f498fe",
   "metadata": {},
   "source": [
    "**Checking model performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66cde29",
   "metadata": {},
   "source": [
    "- The reported average includes the macro average which averages the unweighted mean per label, and the weighted average i.e. averaging the support-weighted mean per label.\n",
    "- In classification, the class of interest is considered the positive class. Here, the class of interest is 1 i.e. identifying  the customers who are at risk of attrition.\n",
    "\n",
    "**Reading the confusion matrix (clockwise):**\n",
    "\n",
    "* True Negative (Actual=0, Predicted=0): Model predicts that a customer would not attrite and the customer does not attrite \n",
    "\n",
    "* False Positive (Actual=0, Predicted=1): Model predicts that a customer would attrite but the customer does not attrite\n",
    "\n",
    "* False Negative (Actual=1, Predicted=0): Model predicts that a customer would not attrite but the customer attrites\n",
    "\n",
    "* True Positive (Actual=1, Predicted=1): Model predicts that a customer would attrite and the customer actually attrites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa973d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting logistic regression model\n",
    "lg=LogisticRegression()\n",
    "lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4402c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the performance on the training data\n",
    "y_pred_train = lg.predict(X_train)\n",
    "metrics_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the performance on the test dataset\n",
    "y_pred_test = lg.predict(X_test)\n",
    "metrics_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30d828",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- **We are getting an accuracy of around 90%** on train and test dataset.\n",
    "- However, **the recall for this model is only around 44% for class 1 on train and test dataset.**\n",
    "- As the recall is low, **this model will not perform well** in differentiating out those customers who have a high chance of leaving the bank, meaning it will eventually not help in reducing the attrition rate. \n",
    "- As we can see from the Confusion Matrix, **this model fails to identify the majority of customers who will attire.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d67f16",
   "metadata": {},
   "source": [
    "**Let's check the coefficients and find which variables are leading to attrition and which can help to reduce the attrition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the coefficients of logistic regression\n",
    "cols=X_train.columns\n",
    "\n",
    "coef_lg=lg.coef_\n",
    "\n",
    "pd.DataFrame(coef_lg,columns=cols).T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad32425",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "\n",
    "**Features which positively affect on the attrition rate are:**\n",
    "- Contacts_Count_12_mon\n",
    "- Months_Inactive_12_mon\n",
    "- Dependent_count\n",
    "- Customer_Age\n",
    "- Income_Category_Less than $40K\t\n",
    "- Education_Level_Graduate\t\n",
    "- Education_Level_Post-Graduate\n",
    "- Education_Level_Doctorate\n",
    "- Avg_Utilization_Ratio\n",
    "\n",
    "**Features which negatively affect on the attrition rate are:**\n",
    "- Total_Relationship_Count\t\n",
    "- Total_Trans_Ct\n",
    "- Months_on_book\n",
    "- Total_Ct_Chng_Q4_Q1\n",
    "- Marital_Status_Married\n",
    "- Income_Category_ 60𝐾− 80K\n",
    "- Total_Amt_Chng_Q4_Q1\n",
    "\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- Based on the Logistic Regression model, **Contacts_Count_12_mon is the most important feature** in detecting whether an customer would attrite or not.So, highest attrition is among the customers who interacted the most with the bank.\n",
    "This signifies that the bank is not able to resolve the problems faced by customers leading to attrition\n",
    "- **This model also suggests that attrition is dependent on the customers's activity.** As inactivity increases attrition also increases.\n",
    "- **Dependent_count is an important variable in predicting the attrition rate.** As more the number of dependents more is the attrition, more responsibilities might lead to financial instability in such customers.\n",
    "- Education level of customers also have some interesting outcome.Customers with higher education - Doctorates and Post Graduates are the ones most attriting.\n",
    "- *The customers belonging to the income group - Earning less than 40K are the ones attriting the most.\n",
    "- Other features which appear to affect the chances of attrition are Maritial Status,Avg Utilization ratio.\n",
    "\n",
    "- The model also captures the **inverse relation between Total_Relationship_Count and attrition** - suggesting customer who uses more number of products from the bank are the ones least attriting, such customers might be more financially stable and actively invest in different services provided by the bank.\n",
    "-  **Customers who are doing more transactions with the bank have lower chance of attrition**, a conclusion that makes sense since Less number of transactions lead to higher attrition.\n",
    "- From Total_Ct_Chng_Q4_Q1 and Total_Amt_Chng_Q4_Q1 it's clear that Customers who didn't attrite showed less variability across Q4 to Q1 as compared to the ones who attrited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6fd6c",
   "metadata": {},
   "source": [
    "The coefficients of the logistic regression model give us the log of odds, which is hard to interpret in the real world. We can convert the log of odds into real odds by taking its exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = np.exp(lg.coef_[0]) #finding the odds\n",
    "\n",
    "# adding the odds to a dataframe and sorting the values\n",
    "pd.DataFrame(odds, X_train.columns, columns=['odds']).sort_values(by='odds', ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e137449",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The odds of a customers contacting with the bank more to attrite are **1.3 times** the odds of one who is not, probably due to the fact that the bank is not able to resolve the problems faced by customers leading to attrition.\n",
    "- The odds of a customer being inactive to attrite are **1.2 times** the odds of a customer who is actively in touch with bank.\n",
    "- The odds of a customer with more dependent attriting are **1.2 times** the odds of a customer with less or no dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43ae41",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve for logistic regression**\n",
    "\n",
    "**Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_lg=lg.predict_proba(X_train) #predict_proba gives the probability of each observation belonging to each class\n",
    "\n",
    "\n",
    "precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(y_train, y_scores_lg[:,1])\n",
    "\n",
    "#Plot values of precisions, recalls, and thresholds\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(thresholds_lg, precisions_lg[:-1], 'b--', label='precision')\n",
    "plt.plot(thresholds_lg, recalls_lg[:-1], 'g--', label = 'recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the exact threshold where precision and recall are equal.\n",
    "for i in np.arange(len(thresholds_lg)):\n",
    "    if precisions_lg[i]==recalls_lg[i]:\n",
    "        print(thresholds_lg[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45767415",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- We can see that precision and recall are balanced for a threshold of about ~**0.35**.\n",
    "\n",
    "**Let's find out the performance of the model at this threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_train = lg.predict_proba(X_train)\n",
    "metrics_score(y_train, y_pred_train[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c24c9",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- **The model performance has improved. The recall has increased significantly for class 1.**\n",
    "- Let's check the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_test = lg.predict_proba(X_test)\n",
    "metrics_score(y_test, y_pred_test[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b8321a",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- The model is giving **similar performance on the test and train data** i.e. the model is giving a generalized performance.\n",
    "- **The recall of the test data has increased significantly** while at the same time, the precision has decreased slightly, which is to be expected while adjusting the threshold.\n",
    "- The average recall and precision for the model are good but let's see if we can get better performance using other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f34ed",
   "metadata": {},
   "source": [
    "### Building SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Speed-Up SVM\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93781839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting SVM\n",
    "svm = SVC(kernel = 'linear') #linear kernal or linear decision boundary\n",
    "model = svm.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_svm = model.predict(X_train)\n",
    "metrics_score(y_train, y_pred_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the test data\n",
    "y_pred_test_svm = model.predict(X_test)\n",
    "metrics_score(y_test, y_pred_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf7b64",
   "metadata": {},
   "source": [
    "* SVM model with rbf linear is not overfitting as the accuracy is around 90% for both train and test dataset.\n",
    "* Recall of class 1 for the model is only around 55% which implies our model will not correctly predict the customers who are likely to attrite. \n",
    "* The precision is quite good and the model will help to find true positive and will save the cost and energy of the bank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_thre=SVC(probability=True)\n",
    "svm_thre.fit(X_train,y_train)\n",
    "y_scores_svm=svm_thre.predict_proba(X_train) #predict_proba gives the probability of each observation belonging to each class\n",
    "\n",
    "\n",
    "precisions_svm, recalls_svm, thresholds_svm = precision_recall_curve(y_train, y_scores_svm[:,1])\n",
    "\n",
    "#Plot values of precisions, recalls, and thresholds\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(thresholds_svm, precisions_svm[:-1], 'b--', label='precision')\n",
    "plt.plot(thresholds_svm, recalls_svm[:-1], 'g--', label = 'recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7aa947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the exact threshold where precision and recall are equal.\n",
    "for i in np.arange(len(thresholds_svm)):\n",
    "    if precisions_svm[i]==recalls_svm[i]:\n",
    "        print(thresholds_svm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ef31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold1=0.31\n",
    "y_pred_train = svm_thre.predict_proba(X_train)\n",
    "metrics_score(y_train, y_pred_train[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c03a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = svm_thre.predict_proba(X_test)\n",
    "metrics_score(y_test, y_pred_test[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b705d4",
   "metadata": {},
   "source": [
    "* At the optimal threshold of .31, the model performance has improved significantly. The recall has improved from 0.55 to .75 which is a ~20% increase and the model is giving good generalized results. \n",
    "* Moreover, the kernel used to create this is rbf, hence model is performing good with non-linear kernel.\n",
    "* As the recall is good, **this model will perform well** in differentiating out those customers who have a high chance of leaving the bank, meaning it will eventually help in reducing the attrition rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142eed6d",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop([\"Attrition_Flag\"], axis=1)\n",
    "Y = data1[\"Attrition_Flag\"]\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Splitting data in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec17627",
   "metadata": {},
   "source": [
    "### Building Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt= DecisionTreeClassifier(random_state=1,max_depth=8)\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896e618",
   "metadata": {},
   "source": [
    "#### Checking model performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_dt = model_dt.predict(X_train)\n",
    "metrics_score(y_train, pred_train_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758d145",
   "metadata": {},
   "source": [
    "* Almost 0 errors on the training set, each sample has been classified correctly.\n",
    "* Model has performed very well on the training set.\n",
    "* As we know a decision tree will continue to grow and classify each data point correctly if no restrictions are applied as the trees will learn all the patterns in the training set.\n",
    "* Let's check the performance on test data to see if the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_dt = model_dt.predict(X_test)\n",
    "metrics_score(y_test, pred_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68f9df",
   "metadata": {},
   "source": [
    "* The decision tree model is slightly overfitting the data here.\n",
    "* We can tune the hyperparameters to increase the performance and reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15797fde",
   "metadata": {},
   "source": [
    "**Let's visualize the decision tree** and observe the decision rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b74a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "from sklearn import tree\n",
    "tree.plot_tree(model_dt,feature_names=features,max_depth =4, filled=True,fontsize=9,node_ids=True,class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of features in the tree building\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "importances = model_dt.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33135810",
   "metadata": {},
   "source": [
    "- **So,Total_Trans_Ct  is the most important feature** **followed by Total_Revolving_Bal and Total_Trans_Amt** which makes sense.Customers who are doing more transactions with the bank have lower chance of attrition.\n",
    "- **Total_Ct_Chng_Q4_Q1, Total_Relationship_Count, Total_Amt_Chng_Q4_Q1 are also  important factors** ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299cc01",
   "metadata": {},
   "source": [
    "## Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5287449",
   "metadata": {},
   "source": [
    "* We have been able to build a predictive model:\n",
    "\n",
    "  a) that bank can deploy this model to identify customers who are at the risk of attrition.\n",
    "  \n",
    "  b) that the bank can use to find the key causes that drive attrition. \n",
    "  \n",
    "  c) based on which bank can take appropriate actions to build better retention policies for customers.\n",
    "  \n",
    "\n",
    "* Factors that drive the attrition - Total_Trans_Ct, Total_Revolving_Bal, Total_Trans_Amt, Total_Relationship_Count\n",
    "* Total_Trans_Ct: Less number of transactions in a year leads to attrition of a customer - to increase the usage of cards the bank can provide offers like cashback, special discounts on the purchase of something, etc so that customers feel motivated to use their cards.\n",
    "\n",
    "* Total_Revolving_Bal: Customers with less total revolving balance are the ones who attrited, such customers must have cleared their dues and opted out of the credit card service. After the customer has cleared the dues bank can ask for feedback on their experience and get to the cause of attrition.\n",
    "\n",
    "* Total_Trans_Amt: Less number of transactions can lead to less transaction amount and eventually leads to customer attrition - Bank can provide offers on the purchase of costlier items which in turn will benefit the customers and bank both.\n",
    "\n",
    "* Total_Relationship_Count: Attrition is highest among the customers who are using 1 or 2 products offered by the bank - together they constitute ~55% of the attrition - Bank should investigate here to find the problems customers are facing with these products, customer support, or more transparency can help in retaining customers.\n",
    "\n",
    "* Female customers should be the target customers for any kind of marketing campaign as they are the ones who utilize their credits, make more and higher amount transactions. But their credit limit is less so increasing the credit limit for such customers can profit the bank.\n",
    "\n",
    "* Months_Inactive: As inactivity increases the attrition also increases, 2-4 months of inactivity are the biggest contributors of attrition -Bank can send automated messages to engage customers, these messages can be about their monthly activity, new offers or services, etc.\n",
    "\n",
    "* Highest attrition is among the customers who interacted/reached out the most with/to the bank, This indicates that the bank is not able to resolve the problems faced by customers leading to attrition - a feedback collection system can be set up to check if the customers are satisfied with the resolution provided, if not, the bank should act upon it accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ea45a68df6c081ed75564725b0d139197db1d4205c00e9c49160b50bc65c42b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
